{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from jupyter_dash import JupyterDash\n",
    "import dash\n",
    "from dash import dcc, html, dash_table\n",
    "from dash.dependencies import Input, Output, State\n",
    "import dash_bootstrap_components as dbc\n",
    "\n",
    "zip_file_path = \"Data.zip\"\n",
    "extract_path = \"extracted_data\"\n",
    "os.makedirs(extract_path, exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "years = list(range(2014, 2025))\n",
    "quarters = [\"QTR1\", \"QTR2\", \"QTR3\", \"QTR4\"]\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for year in years:\n",
    "    for quarter in quarters:\n",
    "        file_path = os.path.join(extract_path, f\"{year}_{quarter}.csv\")\n",
    "        if os.path.exists(file_path):\n",
    "            df = pd.read_csv(file_path)\n",
    "            df[\"Year\"] = year\n",
    "            df[\"Quarter\"] = quarter\n",
    "            all_data.append(df)\n",
    "\n",
    "if not all_data:\n",
    "    raise ValueError(\"No data was found. Ensure the ZIP file contains valid CSV files.\")\n",
    "df_filings = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "\n",
    "# Store full dataset before filtering (for export)\n",
    "df_full_data = df_filings.copy()\n",
    "\n",
    "\n",
    "# Ensure necessary columns exist\n",
    "required_columns = [\"Central Index Key\",\"Year\", \"Quarter\", \"State or Country - Full - Physical Location\", \"Total Amount Offered\"]\n",
    "df_filings = df_filings[required_columns].dropna()\n",
    "\n",
    "# Rename columns for usability\n",
    "df_filings = df_filings.rename(columns={\"State or Country - Full - Physical Location\": \"State\"})\n",
    "\n",
    "# Convert \"Total Amount Offered\" to numeric, handling \"Indefinite\" cases\n",
    "df_filings[\"Total Amount Offered\"] = pd.to_numeric(df_filings[\"Total Amount Offered\"], errors=\"coerce\")\n",
    "df_filings[\"Total Amount Offered\"] = df_filings[\"Total Amount Offered\"].fillna(0)\n",
    "print(df_filings.head(5))\n",
    "print(df_full_data.head(5))\n",
    "\n",
    "app = JupyterDash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "\n",
    "app.layout = dbc.Container([\n",
    "    html.H1(\"SEC D-Type Filings Filter\", className=\"text-center mt-4\"),\n",
    "\n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            dcc.Dropdown(\n",
    "                id=\"year-dropdown\",\n",
    "                options=[{\"label\": str(y), \"value\": y} for y in sorted(df_filings[\"Year\"].unique())],\n",
    "                placeholder=\"Select Year\",\n",
    "                multi=True\n",
    "            ),\n",
    "        ], width=3),\n",
    "\n",
    "        dbc.Col([\n",
    "            dcc.Dropdown(\n",
    "                id=\"quarter-dropdown\",\n",
    "                options=[{\"label\": q, \"value\": q} for q in sorted(df_filings[\"Quarter\"].unique())],\n",
    "                placeholder=\"Select Quarter\",\n",
    "                multi=True\n",
    "            ),\n",
    "        ], width=3),\n",
    "\n",
    "        dbc.Col([\n",
    "            dcc.Dropdown(\n",
    "                id=\"state-dropdown\",\n",
    "                options=[{\"label\": s, \"value\": s} for s in sorted(df_filings[\"State\"].dropna().unique())],\n",
    "                placeholder=\"Select State\",\n",
    "                multi=True\n",
    "            ),\n",
    "        ], width=3),\n",
    "    ], className=\"mb-3\"),\n",
    "\n",
    "    dbc.Row([\n",
    "    dbc.Col([\n",
    "        html.Label(\"Total Amount Offered (USD)\", className=\"font-weight-bold\"), \n",
    "        dcc.RangeSlider(\n",
    "            id=\"amount-slider\",\n",
    "            min=df_filings[\"Total Amount Offered\"].min(),\n",
    "            max=df_filings[\"Total Amount Offered\"].max(),\n",
    "            step=10000,\n",
    "            marks={int(x): f\"${x:,}\" for x in range(0, int(df_filings[\"Total Amount Offered\"].max()), 50000000)},\n",
    "            value=[df_filings[\"Total Amount Offered\"].min(), df_filings[\"Total Amount Offered\"].max()],\n",
    "            tooltip={\"placement\": \"bottom\", \"always_visible\": True}  \n",
    "        ),\n",
    "        html.Div(id=\"amount-slider-output\", className=\"text-center mt-2 font-italic\"), \n",
    "    ], width=9),\n",
    "], className=\"mb-3\"),\n",
    "\n",
    "\n",
    "    html.Div(id=\"data-count\", className=\"text-center mt-3 mb-3 font-weight-bold\"),\n",
    "\n",
    "    dash_table.DataTable(\n",
    "        id=\"table\",\n",
    "        columns=[{\"name\": col, \"id\": col} for col in df_filings.columns],\n",
    "        page_size=0,\n",
    "        style_table={\"overflowX\": \"auto\"}\n",
    "    ),\n",
    "\n",
    "    html.Button(\"Export to CSV\", id=\"export-btn\", n_clicks=0, className=\"btn btn-primary mt-3\"),\n",
    "    dcc.Download(id=\"download-dataframe-csv\")\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"table\", \"data\"),\n",
    "    Output(\"data-count\", \"children\"),\n",
    "    Input(\"year-dropdown\", \"value\"),\n",
    "    Input(\"quarter-dropdown\", \"value\"),\n",
    "    Input(\"state-dropdown\", \"value\"),\n",
    "    Input(\"amount-slider\", \"value\"),\n",
    ")\n",
    "def update_table(selected_years, selected_quarters, selected_states, amount_range):\n",
    "    filtered_df = df_filings  # Only filtering on selected columns\n",
    "\n",
    "    if selected_years:\n",
    "        filtered_df = filtered_df[filtered_df[\"Year\"].isin(selected_years)]\n",
    "    if selected_quarters:\n",
    "        filtered_df = filtered_df[filtered_df[\"Quarter\"].isin(selected_quarters)]\n",
    "    if selected_states:\n",
    "        filtered_df = filtered_df[filtered_df[\"State\"].isin(selected_states)]\n",
    "    if amount_range:\n",
    "        filtered_df = filtered_df[\n",
    "            (filtered_df[\"Total Amount Offered\"] >= amount_range[0]) &\n",
    "            (filtered_df[\"Total Amount Offered\"] <= amount_range[1])\n",
    "        ]\n",
    "\n",
    "    count_text = f\"Total Filings Found: {len(filtered_df)}\"\n",
    "    return filtered_df.to_dict(\"records\"), count_text\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"download-dataframe-csv\", \"data\"),\n",
    "    Input(\"export-btn\", \"n_clicks\"),  # Only triggers on button click\n",
    "    State(\"year-dropdown\", \"value\"),\n",
    "    State(\"quarter-dropdown\", \"value\"),\n",
    "    State(\"state-dropdown\", \"value\"),\n",
    "    State(\"amount-slider\", \"value\"),\n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def export_csv(n_clicks, selected_years, selected_quarters, selected_states, amount_range):\n",
    "    filtered_df = df_filings \n",
    "\n",
    "    if selected_years:\n",
    "        filtered_df = filtered_df[filtered_df[\"Year\"].isin(selected_years)]\n",
    "    if selected_quarters:\n",
    "        filtered_df = filtered_df[filtered_df[\"Quarter\"].isin(selected_quarters)]\n",
    "    if selected_states:\n",
    "        filtered_df = filtered_df[filtered_df[\"State\"].isin(selected_states)]\n",
    "    if amount_range:\n",
    "        filtered_df = filtered_df[\n",
    "            (filtered_df[\"Total Amount Offered\"] >= amount_range[0]) &\n",
    "            (filtered_df[\"Total Amount Offered\"] <= amount_range[1])\n",
    "        ]\n",
    "\n",
    "    matching_ids = filtered_df[\"Central Index Key\"].unique()  # Extract unique IDs from filtered data\n",
    "    full_filtered_df = df_full_data[df_full_data[\"Central Index Key\"].isin(matching_ids)]  # Match with full dataset\n",
    "\n",
    "    if full_filtered_df.empty:\n",
    "        return dash.no_update \n",
    "\n",
    "    return dcc.send_data_frame(full_filtered_df.to_csv, \"filtered_sec_filings.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# Run the Dash app inside Jupyter Notebook\n",
    "app.run_server(mode=\"inline\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import os\n",
    "#Data filter for growth in fillings by US state, input the state abbreviation for the filter to work \n",
    "\n",
    "years = list(range(2014, 2025))  # From 2014 to 2024\n",
    "quarters = [\"QTR1\", \"QTR2\", \"QTR3\", \"QTR4\"]\n",
    "\n",
    "# State abbreviations and full names\n",
    "all_states = [\n",
    "    \"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\", \n",
    "    \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \n",
    "    \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \n",
    "    \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \n",
    "    \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"\n",
    "]\n",
    "state_full_names = [\n",
    "    \"ALABAMA\", \"ALASKA\", \"ARIZONA\", \"ARKANSAS\", \"CALIFORNIA\", \"COLORADO\", \"CONNECTICUT\", \n",
    "    \"DELAWARE\", \"FLORIDA\", \"GEORGIA\", \"HAWAII\", \"IDAHO\", \"ILLINOIS\", \"INDIANA\", \"IOWA\", \n",
    "    \"KANSAS\", \"KENTUCKY\", \"LOUISIANA\", \"MAINE\", \"MARYLAND\", \"MASSACHUSETTS\", \"MICHIGAN\", \n",
    "    \"MINNESOTA\", \"MISSISSIPPI\", \"MISSOURI\", \"MONTANA\", \"NEBRASKA\", \"NEVADA\", \"NEW HAMPSHIRE\", \n",
    "    \"NEW JERSEY\", \"NEW MEXICO\", \"NEW YORK\", \"NORTH CAROLINA\", \"NORTH DAKOTA\", \"OHIO\", \n",
    "    \"OKLAHOMA\", \"OREGON\", \"PENNSYLVANIA\", \"RHODE ISLAND\", \"SOUTH CAROLINA\", \"SOUTH DAKOTA\", \n",
    "    \"TENNESSEE\", \"TEXAS\", \"UTAH\", \"VERMONT\", \"VIRGINIA\", \"WASHINGTON\", \"WEST VIRGINIA\", \n",
    "    \"WISCONSIN\", \"WYOMING\"\n",
    "]\n",
    "\n",
    "state_name_to_abbreviation = dict(zip(state_full_names, all_states))\n",
    "\n",
    "zip_file_path = \"Data.zip\"\n",
    "extract_path = \"extracted_data\"\n",
    "\n",
    "os.makedirs(extract_path, exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for year in years:\n",
    "    for quarter in quarters:\n",
    "        csv_file_name = f\"{year}_{quarter}.csv\"\n",
    "        file_path = os.path.join(extract_path, csv_file_name)\n",
    "        \n",
    "        if os.path.exists(file_path):\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            jurisdiction_counts = (\n",
    "                df[\"State or Country - Legal Jurisdiction\"]\n",
    "                .map(state_name_to_abbreviation)\n",
    "                .value_counts()\n",
    "                .reset_index()\n",
    "            )\n",
    "            jurisdiction_counts.columns = [\"State\", \"JurisdictionCount\"]\n",
    "\n",
    "            state_counts_simple = (\n",
    "                df[\"State or Country - Physical Location\"]\n",
    "                .value_counts()\n",
    "                .reset_index()\n",
    "            )\n",
    "            state_counts_simple.columns = [\"State\", \"TotalCount\"]\n",
    "            state_counts_simple[\"TotalCount\"] = state_counts_simple[\"TotalCount\"].fillna(0).astype(int)\n",
    "\n",
    "            merged_counts = pd.merge(\n",
    "                jurisdiction_counts, state_counts_simple, on=\"State\", how=\"outer\"\n",
    "            ).fillna(0)\n",
    "\n",
    "            merged_counts[\"Percentage\"] = (\n",
    "                (merged_counts[\"JurisdictionCount\"] / merged_counts[\"TotalCount\"]) * 100\n",
    "            ).fillna(0)\n",
    "\n",
    "            merged_counts[\"Year\"] = year\n",
    "            merged_counts[\"Quarter\"] = quarter\n",
    "            \n",
    "            all_data.append(merged_counts)\n",
    "final_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "final_df = final_df.sort_values(by=[\"State\", \"Year\"])\n",
    "\n",
    "final_df[\"PercentageGrowth\"] = (\n",
    "    (final_df[\"Percentage\"] - final_df.groupby(\"State\")[\"Percentage\"].shift(4)) /\n",
    "    final_df.groupby(\"State\")[\"Percentage\"].shift(4)\n",
    ") * 100\n",
    "\n",
    "final_df[\"PercentageGrowth\"] = final_df[\"PercentageGrowth\"].fillna(0)\n",
    "selected_state = input(\"Enter the state abbreviation (e.g., CA, TX, NY): \").upper()\n",
    "\n",
    "state_data = final_df[final_df[\"State\"] == selected_state]\n",
    "\n",
    "if state_data.empty:\n",
    "    print(f\"No data found for state: {selected_state}\")\n",
    "else:\n",
    "    \n",
    "    fig_growth = px.line(\n",
    "        state_data,\n",
    "        x=\"Year\",\n",
    "        y=\"PercentageGrowth\",\n",
    "        title=f\"Yearly Jurisdiction Percentage Growth in {selected_state} (2014-2024)\",\n",
    "        labels={\"PercentageGrowth\": \"Percentage Growth (%)\"},\n",
    "    )\n",
    "\n",
    "\n",
    "fig_growth.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import os\n",
    "all_states = [\n",
    "    \"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\", \n",
    "    \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \n",
    "    \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \n",
    "    \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \n",
    "    \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"\n",
    "]\n",
    "state_full_names = [\n",
    "    \"ALABAMA\", \"ALASKA\", \"ARIZONA\", \"ARKANSAS\", \"CALIFORNIA\", \"COLORADO\", \"CONNECTICUT\", \n",
    "    \"DELAWARE\", \"FLORIDA\", \"GEORGIA\", \"HAWAII\", \"IDAHO\", \"ILLINOIS\", \"INDIANA\", \"IOWA\", \n",
    "    \"KANSAS\", \"KENTUCKY\", \"LOUISIANA\", \"MAINE\", \"MARYLAND\", \"MASSACHUSETTS\", \"MICHIGAN\", \n",
    "    \"MINNESOTA\", \"MISSISSIPPI\", \"MISSOURI\", \"MONTANA\", \"NEBRASKA\", \"NEVADA\", \"NEW HAMPSHIRE\", \n",
    "    \"NEW JERSEY\", \"NEW MEXICO\", \"NEW YORK\", \"NORTH CAROLINA\", \"NORTH DAKOTA\", \"OHIO\", \n",
    "    \"OKLAHOMA\", \"OREGON\", \"PENNSYLVANIA\", \"RHODE ISLAND\", \"SOUTH CAROLINA\", \"SOUTH DAKOTA\", \n",
    "    \"TENNESSEE\", \"TEXAS\", \"UTAH\", \"VERMONT\", \"VIRGINIA\", \"WASHINGTON\", \"WEST VIRGINIA\", \n",
    "    \"WISCONSIN\", \"WYOMING\"\n",
    "]\n",
    "\n",
    "zip_file_path = \"Data.zip\"\n",
    "csv_file_name = \"2022_QTR4.csv\"\n",
    "extract_path = \"extracted_data\" \n",
    "zip_file_path = \"Data.zip\"\n",
    "\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    file_list = zip_ref.namelist()\n",
    "\n",
    "print(\"Files inside ZIP:\", file_list)\n",
    "\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extract(csv_file_name, \"extracted_data\")\n",
    "\n",
    "df = pd.read_csv(f\"extracted_data/{csv_file_name}\")\n",
    "\n",
    "state_name_to_abbreviation = dict(zip(state_full_names, all_states))\n",
    "\n",
    "jurisdiction_counts = (\n",
    "    df[\"State or Country - Legal Jurisdiction\"]\n",
    "    .map(state_name_to_abbreviation)\n",
    "    .value_counts()  \n",
    "    .reset_index()\n",
    ")\n",
    "jurisdiction_counts.columns = [\"State\", \"JurisdictionCount\"]\n",
    "state_counts_simple = (\n",
    "    df[\"State or Country - Physical Location\"]\n",
    "    .value_counts()\n",
    "    .reset_index()\n",
    ")\n",
    "state_counts_simple.columns = [\"State\", \"TotalCount\"]\n",
    "state_counts_simple[\"TotalCount\"] = state_counts_simple[\"TotalCount\"].fillna(0).astype(int)\n",
    "print(state_counts_simple)\n",
    "\n",
    "merged_counts = pd.merge(\n",
    "    jurisdiction_counts, state_counts_simple, on=\"State\", how=\"outer\"\n",
    ").fillna(0)\n",
    "\n",
    "merged_counts[\"Percentage\"] = (\n",
    "    (merged_counts[\"JurisdictionCount\"] / merged_counts[\"TotalCount\"]) * 100\n",
    ").fillna(0)\n",
    "\n",
    "merged_counts = merged_counts[[\"State\", \"Percentage\"]]\n",
    "print(merged_counts.head(55))\n",
    "\n",
    "fig_simple = px.choropleth(\n",
    "    merged_counts,\n",
    "    locations=\"State\",\n",
    "    locationmode=\"USA-states\",\n",
    "    color=\"Percentage\",\n",
    "    range_color=(0,100),\n",
    "    scope=\"usa\",\n",
    "    color_continuous_scale=\"Viridis\",\n",
    "    title=\"Count of D type fillings by US state, state of filling vs company location\"\n",
    ")\n",
    "\n",
    "fig_simple.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import zipfile\n",
    "import  plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "zip_file_path = \"Data.zip\"\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"extracted_data\") \n",
    "\n",
    "\n",
    "csv_file_path = \"extracted_data/2022_QTR3.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "total_income_by_state = (\n",
    "    df.groupby(df[\"State or Country - Physical Location\"])[\"Total Amount Sold So Far\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "total_income_by_state.columns = [\"State\", \"TotalIncome\" ]\n",
    "\n",
    "fig_income = px.choropleth(\n",
    "    total_income_by_state,\n",
    "    locations=\"State\",\n",
    "    locationmode=\"USA-states\",\n",
    "    color=\"TotalIncome\",\n",
    "    scope=\"usa\",\n",
    "    color_continuous_scale=\"Viridis\",\n",
    "    title=\"Total Income Raised by State\",\n",
    "    labels={\"TotalIncome\": \"Total Income ($)\"}\n",
    ")\n",
    "\n",
    "fig_income.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def versatile_filter(df):\n",
    "    global filtered_df\n",
    "    # Create an \"all True\" Series that we can use as our starting mask\n",
    "    mask_state = pd.Series(True, index=df.index)\n",
    "    mask_subed = pd.Series(True, index=df.index)\n",
    "    mask_amount = pd.Series(True, index=df.index)\n",
    "    mask_equity = pd.Series(True, index=df.index)\n",
    "    mask_industry = pd.Series(True, index=df.index)\n",
    "    \n",
    "    applied_filters = []\n",
    "\n",
    "    # Ask the user whether they want to filter the data at all\n",
    "    while True:\n",
    "        user_filter = input(\"Would you like to filter the data? (yes/no): \").strip().lower()\n",
    "        if user_filter in [\"yes\", \"no\"]:\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid input. Please enter 'yes' or 'no'.\")\n",
    "    if user_filter != \"yes\":\n",
    "        print(\"Displaying sample of the full data:\")\n",
    "        filtered_df = df\n",
    "        return filtered_df.sample(n=min(10, len(df)))[[\"Central Index Key\", \"Name of the Entity\", \"Address\", \"Address - Specification\", \"City\", \"State or Country - Physical Location\", \"State or Country - Full - Physical Location\", \"Zip Code / Postal Code\", \"Issuer Phone Number\", \"State or Country - Legal Jurisdiction\", \"Minimum Investment Amount Accepted\", \"Total Amount Offered\", \"Total Amount Sold So Far\", \"Total Amount Remaining to be sold\", \"Clarifications Regarding the Offering and Sales amounts\", \"Is the Entity Offering Equity\", \"Industry\"]]\n",
    "\n",
    "    # List of available filters\n",
    "    available_filters = [\"state\", \"fully_subscribed\", \"amount\", \"equity\", \"industry\"]\n",
    "\n",
    "    # Loop: let the user update or add filters until they are satisfied\n",
    "    while True:\n",
    "        print(\"\\nAvailable filters:\")\n",
    "        print(\"  state             : Filter by state abbreviation\")\n",
    "        print(\"  fully_subscribed  : Filter by fully subscribed offerings\")\n",
    "        print(\"  amount            : Filter by offered funding amount range\")\n",
    "        print(\"  equity            : Filter by equity offerings\")\n",
    "        print(\"  industry          : Filter by industry\")\n",
    "        chosen_filter = input(\"Which filter would you like to apply/update? (state/fully_subscribed/amount/equity/industry): \").strip().lower()\n",
    "        \n",
    "        if chosen_filter not in available_filters:\n",
    "            print(\"Invalid filter type. Please choose one of the available filters.\")\n",
    "            continue\n",
    "\n",
    "        # Filter by state\n",
    "        if chosen_filter == \"state\":\n",
    "            action = input(\"Would you like to apply or delete the state filter? (apply/delete): \").strip().lower()\n",
    "            while action not in [\"apply\", \"delete\"]:\n",
    "                action = input(\"Invalid input. Please enter 'apply' or 'delete': \").strip().lower()\n",
    "            if action == \"delete\":\n",
    "                mask_state = pd.Series(True, index=df.index)\n",
    "                applied_filters = [f for f in applied_filters if not f.startswith(\"State:\")]\n",
    "                print(\"State filter deleted.\")\n",
    "            else:\n",
    "                state_abbreviations = input(\"Enter one or more state abbreviations separated by commas (e.g., CA,TX,NY): \").upper().split(',')\n",
    "                # Ensure that the abbreviations are valid (assuming all_states is defined)\n",
    "                state_abbreviations = [abbr.strip() for abbr in state_abbreviations if abbr.strip() in all_states]\n",
    "                while not state_abbreviations:\n",
    "                    state_abbreviations = input(\"Invalid state abbreviations. Please try again (e.g., CA,TX,NY): \").upper().split(',')\n",
    "                    state_abbreviations = [abbr.strip() for abbr in state_abbreviations if abbr.strip() in all_states]\n",
    "                # Update the state mask\n",
    "                mask_state = df[\"State or Country - Physical Location\"].isin(state_abbreviations)\n",
    "                applied_filters = [f for f in applied_filters if not f.startswith(\"State:\")]\n",
    "                applied_filters.append(f\"State: {', '.join(state_abbreviations)}\")\n",
    "                print(f\"State filter set to: {', '.join(state_abbreviations)}\")\n",
    "        \n",
    "        # Filter by fully subscribed offerings\n",
    "        elif chosen_filter == \"fully_subscribed\":\n",
    "            action = input(\"Would you like to apply or delete the fully subscribed filter? (apply/delete): \").strip().lower()\n",
    "            while action not in [\"apply\", \"delete\"]:\n",
    "                action = input(\"Invalid input. Please enter 'apply' or 'delete': \").strip().lower()\n",
    "            if action == \"delete\":\n",
    "                mask_subed = pd.Series(True, index=df.index)\n",
    "                applied_filters = [f for f in applied_filters if not f.startswith(\"Fully Subscribed:\")]\n",
    "                print(\"Fully subscribed filter deleted.\")\n",
    "            else:\n",
    "                subed = input(\"Are you interested only in fully subscribed offerings? (yes/no): \").strip().lower()\n",
    "                while subed not in [\"yes\", \"no\"]:\n",
    "                    subed = input(\"Invalid input. Please enter 'yes' or 'no': \").strip().lower()\n",
    "                # Note: adjust the condition below based on how your data represents amounts.\n",
    "                if subed == \"yes\":\n",
    "                    mask_subed = (df[\"Total Amount Remaining to be sold\"] == 0)\n",
    "                    applied_filters = [f for f in applied_filters if not f.startswith(\"Fully Subscribed:\")]\n",
    "                    applied_filters.append(\"Fully Subscribed: Yes\")\n",
    "                    print(\"Filtering for fully subscribed offerings only.\")\n",
    "                else:\n",
    "                    mask_subed = (df[\"Total Amount Remaining to be sold\"] != 0)\n",
    "                    applied_filters = [f for f in applied_filters if not f.startswith(\"Fully Subscribed:\")]\n",
    "                    applied_filters.append(\"Fully Subscribed: No\")\n",
    "                    print(\"Filtering for offerings that are not fully subscribed.\")\n",
    "    \n",
    "        # Filter by funding amount range\n",
    "        elif chosen_filter == \"amount\":\n",
    "            action = input(\"Would you like to apply or delete the amount filter? (apply/delete): \").strip().lower()\n",
    "            while action not in [\"apply\", \"delete\"]:\n",
    "                action = input(\"Invalid input. Please enter 'apply' or 'delete': \").strip().lower()\n",
    "            if action == \"delete\":\n",
    "                mask_amount = pd.Series(True, index=df.index)\n",
    "                applied_filters = [f for f in applied_filters if not f.startswith(\"Amount:\")]\n",
    "                print(\"Amount filter deleted.\")\n",
    "            else:\n",
    "                while True:\n",
    "                    try:\n",
    "                        min_val = int(input(\"Enter the minimum funding amount in USD: \"))\n",
    "                        break\n",
    "                    except ValueError:\n",
    "                        print(\"Invalid input. Please enter an integer value for the minimum funding amount.\")\n",
    "                while True:\n",
    "                    max_input = input(\"Enter the maximum funding amount in USD (or type 'infinite' for no upper limit): \").strip().lower()\n",
    "                    if max_input == \"infinite\":\n",
    "                        max_val = float('inf')\n",
    "                        break\n",
    "                    try:\n",
    "                        max_val = int(max_input)\n",
    "                        break\n",
    "                    except ValueError:\n",
    "                        print(\"Invalid input. Please enter an integer value for the maximum funding amount or 'infinite'.\")\n",
    "                if min_val > max_val:\n",
    "                    print(\"The minimum funding amount cannot be greater than the maximum. Amount filter not applied.\")\n",
    "                else:\n",
    "                    mask_amount = (df[\"Total Amount Offered\"] >= min_val) & (df[\"Total Amount Offered\"] <= max_val)\n",
    "                    applied_filters = [f for f in applied_filters if not f.startswith(\"Amount:\")]\n",
    "                    applied_filters.append(f\"Amount: {min_val} to {max_val}\")\n",
    "                    print(f\"Filtering for funding amounts between {min_val} and {max_val} USD.\")\n",
    "\n",
    "        # Filter by equity offerings\n",
    "        elif chosen_filter == \"equity\":\n",
    "            action = input(\"Would you like to apply or delete the equity filter? (apply/delete): \").strip().lower()\n",
    "            while action not in [\"apply\", \"delete\"]:\n",
    "                action = input(\"Invalid input. Please enter 'apply' or 'delete': \").strip().lower()\n",
    "            if action == \"delete\":\n",
    "                mask_equity = pd.Series(True, index=df.index)\n",
    "                applied_filters = [f for f in applied_filters if not f.startswith(\"Equity:\")]\n",
    "                print(\"Equity filter deleted.\")\n",
    "            else:\n",
    "                equity = input(\"Are you interested only in offerings of equity or offerings excluding equity? (only_equity/excluding_equity): \").strip().lower()\n",
    "                while equity not in [\"only_equity\", \"excluding_equity\"]:\n",
    "                    equity = input(\"Invalid input. Please enter 'only_equity' or 'excluding_equity': \").strip().lower()\n",
    "                if equity == \"only_equity\":\n",
    "                    mask_equity = df[\"Is the Entity Offering Equity\"] == True\n",
    "                    applied_filters = [f for f in applied_filters if not f.startswith(\"Equity:\")]\n",
    "                    applied_filters.append(\"Equity: Only Equity\")\n",
    "                    print(\"Filtering for offerings of equity only.\")\n",
    "                else:\n",
    "                    mask_equity = df[\"Is the Entity Offering Equity\"] != True\n",
    "                    applied_filters = [f for f in applied_filters if not f.startswith(\"Equity:\")]\n",
    "                    applied_filters.append(\"Equity: Excluding Equity\")\n",
    "                    print(\"Filtering for offerings excluding equity.\")\n",
    "        \n",
    "        # Filter by industry\n",
    "        elif chosen_filter == \"industry\":\n",
    "            action = input(\"Would you like to apply or delete the industry filter? (apply/delete): \").strip().lower()\n",
    "            while action not in [\"apply\", \"delete\"]:\n",
    "                action = input(\"Invalid input. Please enter 'apply' or 'delete': \").strip().lower()\n",
    "            if action == \"delete\":\n",
    "                mask_industry = pd.Series(True, index=df.index)\n",
    "                applied_filters = [f for f in applied_filters if not f.startswith(\"Industry:\")]\n",
    "                print(\"Industry filter deleted.\")\n",
    "            else:\n",
    "                while True:\n",
    "                    industry_input = input(\"Enter one or more industries separated by commas (or type 'list' to see all industries) - be case sensitive: \").strip()\n",
    "                    if industry_input.lower() == \"list\":\n",
    "                        print(\"Available industries:\")\n",
    "                        for industry in industries:\n",
    "                            print(f\"  {industry}\")\n",
    "                        continue\n",
    "                    industry_list = [ind.strip() for ind in industry_input.split(',') if ind.strip() in industries]\n",
    "                    if not industry_list:\n",
    "                        print(\"Invalid industries. Please try again.\")\n",
    "                    else:\n",
    "                        break\n",
    "                mask_industry = df[\"Industry\"].isin(industry_list)\n",
    "                applied_filters = [f for f in applied_filters if not f.startswith(\"Industry:\")]\n",
    "                applied_filters.append(f\"Industry: {', '.join(industry_list)}\")\n",
    "                print(f\"Industry filter set to: {', '.join(industry_list)}\")\n",
    "\n",
    "        # Combine all the masks\n",
    "        overall_mask = mask_state & mask_subed & mask_amount & mask_equity & mask_industry\n",
    "\n",
    "        # Show a sample of the filtered data\n",
    "        filtered_df = df[overall_mask]\n",
    "        if filtered_df.empty:\n",
    "            print(\"\\nNo data matches the current filter criteria.\")\n",
    "        else:\n",
    "            print(\"\\nHere is a sample of the filtered data:\")\n",
    "            print(\"Applied Filters- \" + \"; \".join(applied_filters))\n",
    "            display(filtered_df.sample(n=min(10, len(filtered_df)))[[\"Central Index Key\", \"Name of the Entity\", \"Address\", \"Address - Specification\", \"City\", \"State or Country - Physical Location\", \"State or Country - Full - Physical Location\", \"Zip Code / Postal Code\", \"Issuer Phone Number\", \"State or Country - Legal Jurisdiction\", \"Minimum Investment Amount Accepted\", \"Total Amount Offered\", \"Total Amount Sold So Far\", \"Total Amount Remaining to be sold\", \"Clarifications Regarding the Offering and Sales amounts\", \"Is the Entity Offering Equity\", \"Industry\"]])\n",
    "        \n",
    "        # Ask if the user wants to apply/update another filter\n",
    "        continue_filter = input(\"Would you like to apply/update another filter? (yes/no): \").strip().lower()\n",
    "        while continue_filter not in [\"yes\", \"no\"]:\n",
    "                continue_filter = input(\"Invalid input. Please enter 'yes' or 'no': \").strip().lower()\n",
    "        if continue_filter != \"yes\":\n",
    "            break\n",
    "\n",
    "    print(\"\\nDisplaying sample of the final filtered data:\")\n",
    "    return filtered_df.sample(n=min(10, len(filtered_df)))\n",
    "\n",
    "versatile_filter(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access denied. Ensure you have a proper User-Agent header.\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "403 Client Error: Forbidden for url: https://www.sec.gov/Archives/edgar/daily-index/2012/QTR3/company.2012111.idx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 53\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccess denied. Ensure you have a proper User-Agent header.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m     exit()\n\u001b[0;32m---> 53\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     56\u001b[0m content \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(content)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1019\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1020\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1021\u001b[0m     )\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://www.sec.gov/Archives/edgar/daily-index/2012/QTR3/company.2012111.idx"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Parsing the XML file to extract the relevant information\n",
    "from sec_edgar_downloader import Downloader\n",
    "#needs to comply with sec privacy :(( )\n",
    "dl = Downloader(\"test\", \"test@test.com\")\n",
    "import pandas as pd \n",
    "import time\n",
    "import requests\n",
    "\n",
    "#sec offers an api to get the daily or quartely indexes, metadata for all fillings\n",
    "#there is no endpoint to specifically search by form type\n",
    "#the actual data can only be downloaded with an accesion number and cik\n",
    "#using cik fetched from daily index, fetch all fillings by company and select those with type D \n",
    "#download the actual file using url from the data line(the current data url returns the entire txt, we only need the actual xml file for the filing ) \n",
    "\n",
    "\n",
    "#used only for gathering data \n",
    "more_data = input(\"Are you interested in more data? (Y/N): \").strip().upper()\n",
    "\n",
    "if more_data != 'Y':\n",
    "    print(\"Exiting script.\")\n",
    "    import sys\n",
    "    sys.exit()\n",
    "\n",
    "year = int(input(\"Enter the year in which you are interested (between 2000 and 2013): \"))\n",
    "\n",
    "if year < 2000 or year > 2013:\n",
    "    print(\"Invalid year. Exiting script.\")\n",
    "    import sys\n",
    "    sys.exit()\n",
    "quarter = int(input(\"Enter the quarter in which you are interested (e.g. 4). \"))\n",
    "month = int(input(\"Enter the month of interest in numerical format (e.g. 11).\"))\n",
    "day = int(input(\"Enter the day of interest in numerical format (e.g. 27).\"))\n",
    "date = f\"{year}{month}{day}\"\n",
    "base_url = 'https://www.sec.gov/Archives/edgar/daily-index'\n",
    "index_url = f'{base_url}/{year}/QTR{quarter}/company.{date}.idx'\n",
    "\n",
    "base_full_index_url ='https://www.sec.gov/Archives/edgar/full-index'\n",
    "#full_index_url =  f'{base_full_index_url}/{year}/QTR{quarter}/company.idx'\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Test (test@test.com)',\n",
    "    'Accept-Encoding': 'gzip, deflate',\n",
    "    'Host': 'www.sec.gov',\n",
    "    'Connection': 'keep-alive',\n",
    "}\n",
    "response = requests.get(index_url, headers=headers)\n",
    "#response = requests.get(full_index_url, headers=headers)\n",
    "\n",
    "if response.status_code == 403:\n",
    "    print(\"Access denied. Ensure you have a proper User-Agent header.\")\n",
    "    exit()\n",
    "\n",
    "response.raise_for_status() \n",
    "\n",
    "\n",
    "content = response.text\n",
    "\n",
    "print(content)\n",
    "lines = content.splitlines()\n",
    "\n",
    "\n",
    "form_d_filings = []\n",
    "\n",
    "\n",
    "\n",
    "header = [\"Company Name\", \"Form Type\", \"CIK\", \"Date Filed\", \"File Name\"]\n",
    "#data lines skip 3 for daily index, 7 for full index \n",
    "#daily index returns idx file with all the fillings for the day, fixed width format, parse it into pandas \n",
    "records = [] \n",
    "#daily index formatting \n",
    "\n",
    "data_lines= lines[3:]\n",
    "for line in data_lines:\n",
    "    if line.strip():  \n",
    "        company_name = line[:60].strip()\n",
    "        form_type = line[60:71].strip()\n",
    "        cik = line[71:82].strip()\n",
    "        date_filed = line[82:92].strip()\n",
    "        file_name = line[92:].strip()\n",
    "        records.append([company_name, form_type, cik, date_filed, file_name])\n",
    "\n",
    "\n",
    "#quarter index formatting \n",
    "'''\n",
    "data_lines=lines[8:]\n",
    "for line in data_lines:\n",
    "    if line.strip():  # Ignore empty lines\n",
    "        company_name = line[0:59].strip()\n",
    "        form_type = line[59:72].strip()\n",
    "        cik = line[72:87].strip()\n",
    "        date_filed = line[87:102].strip()\n",
    "        file_name = line[102:].strip()\n",
    "        \n",
    "        records.append([company_name, form_type, cik, date_filed, file_name])\n",
    "        '''\n",
    "print(records[1])\n",
    "df = pd.DataFrame(records, columns=header)\n",
    "print(response.text)\n",
    "print(len(records))\n",
    "\n",
    "form_d_df = df[df[\"Form Type\"] == \"D\"] \n",
    "row_dict = form_d_df.iloc[1].to_dict()  \n",
    "print(\"Row at index 1 as a dictionary:\")\n",
    "for key, value in row_dict.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "#actual data can be downloaded with CIK and an accession number for the filling\n",
    "form_d_df['Acession_number'] = form_d_df['File Name'].str.split('/').str[-1].str.replace('-', '').str.replace('.txt', '', regex=False)\n",
    "\n",
    "\n",
    "base_url = \"https://www.sec.gov/Archives/edgar/data/\"\n",
    "headers = {\n",
    "    'User-Agent': 'Test (test@test.com)',\n",
    "    'Accept-Encoding': 'gzip, deflate',\n",
    "    'Host': 'www.sec.gov',\n",
    "    'Connection': 'keep-alive',\n",
    "}\n",
    "\n",
    "xml_data_list = []\n",
    "for index, row in form_d_df.iterrows():\n",
    "    print(\"working:\" + row['CIK'])\n",
    "    cik = row['CIK']\n",
    "    accession_number = row['Acession_number']\n",
    "    url = f\"{base_url}{cik}/{accession_number}/primary_doc.xml\"\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            xml_data_list.append(response.text)\n",
    "        else:\n",
    "            xml_data_list.append(f\"Failed for {url} with status code {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        xml_data_list.append(f\"Error for {url}: {str(e)}\")\n",
    "print(len(form_d_df))\n",
    "\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "# Definine parsing function\n",
    "def xml_parse(root):\n",
    "    def extract_text(element, path):\n",
    "        found = element.find(path)\n",
    "        return found.text if found is not None else None\n",
    "\n",
    "    # Parse primary issuer data\n",
    "    primary_issuer = root.find(\".//primaryIssuer\")\n",
    "    if primary_issuer is None:\n",
    "        return None\n",
    "    data_primary_issuer = {\n",
    "        \"Central Index Key\": extract_text(primary_issuer, \".//cik\"),\n",
    "        \"Name of the Entity\": extract_text(primary_issuer, \".//entityName\"),\n",
    "        \"Address\": extract_text(primary_issuer, \".//street1\"),\n",
    "        \"Address - Specification\": extract_text(primary_issuer, \".//street2\"),\n",
    "        \"City\": extract_text(primary_issuer, \".//city\"),\n",
    "        \"State or Country - Physical Location\": extract_text(primary_issuer, \".//stateOrCountry\"),\n",
    "        \"State or Country - Full - Physical Location\": extract_text(primary_issuer, \".//stateOrCountryDescription\"),\n",
    "        \"Zip Code / Postal Code\": extract_text(primary_issuer, \".//zipCode\"),\n",
    "        \"Issuer Phone Number\": extract_text(primary_issuer, \".//issuerPhoneNumber\"),\n",
    "        \"State or Country - Legal Jurisdiction\": extract_text(primary_issuer, \".//jurisdictionOfInc\"),\n",
    "        \"Previous Names Used by the Issuer\": extract_text(primary_issuer, \".//issuerPreviousNameList/value\"),\n",
    "        \"Previous Names from EDGAR\": extract_text(primary_issuer, \".//edgarPreviousNameList/value\"),\n",
    "        \"Type of the Entity\": extract_text(primary_issuer, \".//entityType\"),\n",
    "        \"Type of the Entity - Specification\": extract_text(primary_issuer, \".//entityTypeOtherDesc\"),\n",
    "    }\n",
    "\n",
    "    # Parse related persons data\n",
    "    related_persons = root.findall(\".//relatedPersonsList/relatedPersonInfo\")\n",
    "    data_related_persons = {}\n",
    "    for i, related_person in enumerate(related_persons, start=1):\n",
    "        data_related_persons[f\"First Name - Person {i}\"] = extract_text(related_person, \".//relatedPersonName/firstName\"),\n",
    "        data_related_persons[f\"Last Name - Person {i}\"] = extract_text(related_person, \".//relatedPersonName/lastName\"),\n",
    "        data_related_persons[f\"Associated Address - Person {i}\"] = extract_text(related_person, \".//relatedPersonAddress/street1\"),\n",
    "        data_related_persons[f\"Associated Address - Specification - Person {i}\"] = extract_text(related_person, \".//relatedPersonAddress/street2\"),\n",
    "        data_related_persons[f\"Associated City - Person {i}\"] = extract_text(related_person, \".//relatedPersonAddress/city\"),\n",
    "        data_related_persons[f\"Associated State or Country - Person {i}\"] = extract_text(related_person, \".//relatedPersonAddress/stateOrCountry\"),\n",
    "        data_related_persons[f\"Associated State or Country - Full - Person {i}\"] = extract_text(related_person, \".//relatedPersonAddress/stateOrCountryDescription\"),\n",
    "        data_related_persons[f\"Associated Zip Code - Person {i}\"] = extract_text(related_person, \".//relatedPersonAddress/zipCode\"),\n",
    "\n",
    "        relationships = related_person.findall(\".//relatedPersonRelationshipList/relationship\")\n",
    "        for j, relationship in enumerate(relationships, start=1):\n",
    "            data_related_persons[f\"Relationship {j} with the Entity - Person {i}\"] = relationship.text if relationship is not None else None\n",
    "\n",
    "        data_related_persons[f\"Clarification of the relationship - Person {i}\"] = extract_text(related_person, \".//relationshipClarification\"),\n",
    "\n",
    "    # Parse offering data\n",
    "    offering_data = root.find(\".//offeringData\")\n",
    "    data_offering_data = {\n",
    "        \"Industry\": extract_text(offering_data, \".//industryGroup/industryGroupType\"),\n",
    "        \"Revenue Range of the Entity\": extract_text(offering_data, \".//issuerSize/revenueRange\"),\n",
    "        \"Federal Exemption or Exclusions Claimed by the Entity\": \", \".join([item.text for item in offering_data.findall(\".//federalExemptionsExclusions/item\") if item is not None]) if offering_data is not None else None,\n",
    "        \"Is the Entry an Amendment to Another Filing?\": extract_text(offering_data, \".//typeOfFiling/newOrAmendment/isAmendment\"),\n",
    "        \"Date of the First Sale Under this Filing\": extract_text(offering_data, \".//typeOfFiling/dateOfFirstSale/value\"),\n",
    "        \"Is the Offering Duration Intended to be More Than a Year?\": extract_text(offering_data, \".//durationOfOffering/moreThanOneYear\"),\n",
    "        \"Is the Entity Offering Equity\": extract_text(offering_data, \".//typesOfSecuritiesOffered/isEquityType\"),\n",
    "        \"Is the Entity Creating or Managing a Pooled Fund\": extract_text(offering_data, \".//typesOfSecuritiesOffered/isPooledInvestmentFundType\"),\n",
    "        \"Is the Offering Part of a Business Combination Transaction?\": extract_text(offering_data, \".//isPooledInvestmentFundType/isBusinessCombinationTransaction\"),\n",
    "        \"Is the Offering Part of a Business Combination Transaction? - Clarification\": extract_text(offering_data, \".//businessCombinationTransaction/clarificationOfResponse\"),\n",
    "        \"Minimum Investment Amount Accepted\": extract_text(offering_data, \".//minimumInvestmentAccepted\"),\n",
    "        #\"Entities Compensated for Selling the Securities\": extract_text(offering_data, \".//salesCompensationList\"),\n",
    "        # The line above is commented out because we don't see much use in it\n",
    "        \"Total Amount Offered\": extract_text(offering_data, \".//offeringSalesAmounts/totalOfferingAmount\"),\n",
    "        \"Total Amount Sold So Far\": extract_text(offering_data, \".//offeringSalesAmounts/totalAmountSold\"),\n",
    "        \"Total Amount Remaining to be sold\": extract_text(offering_data, \".//offeringSalesAmounts/totalRemaining\"),\n",
    "        \"Clarifications Regarding the Offering and Sales amounts\": extract_text(offering_data, \".//offeringSalesAmounts/clarificationOfResponse\"),\n",
    "        \"Are Non-accredited Investors Participating in the Offering?\": extract_text(offering_data, \".//investors/hasNonAccreditedInvestors\"),\n",
    "        \"Number of Investors Who Already Invested Under Current Offering\": extract_text(offering_data, \".//investors/totalNumberAlreadyInvested\"),\n",
    "        \"Commision Amount Paid for Sales\": extract_text(offering_data, \".//salesCommissionsFindersFees/salesCommissions/dollarAmount\"),\n",
    "        \"Finder's Fees Amount Paid\": extract_text(offering_data, \".//salesCommissionsFindersFees/findersFees/dollarAmount\"),\n",
    "        \"Clarification Regarding the Finder's Fees Amount Paid\": extract_text(offering_data, \".//salesCommissionsFindersFees/clarificationOfResponse\"),\n",
    "        \"Amount of the Raised Capital Already Used for a Purpose\": extract_text(offering_data, \".//useOfProceeds/grossProceedsUsed/dollarAmount\"),\n",
    "        \"Clarification Regarding the Amount of the Raised Capital Already Used for a Purpose\": extract_text(offering_data, \".//useOfProceeds/clarificationOfResponse\"),\n",
    "        \"Name of the Entity Representative Signing the Filing\": extract_text(offering_data, \".//signatureBlock/authorizedRepresentative\"),\n",
    "        \"Name of the Issuer Entity\": extract_text(offering_data, \".//signatureBlock/signature/issuerName\"),\n",
    "        \"Name of the Person Signing\": extract_text(offering_data, \".//signatureBlock/signature/signatureName\"),\n",
    "        \"Name of the Person Signing - Affirmation\": extract_text(offering_data, \".//signatureBlock/signature/nameOfSigner\"),\n",
    "        \"Title of the Person Signing\": extract_text(offering_data, \".//signatureBlock/signature/signatureTitle\"),\n",
    "        \"Date the Form Was Signed\": extract_text(offering_data, \".//signatureBlock/signature/signatureDate\")\n",
    "    }\n",
    "    # Combine all data\n",
    "    data = {**data_primary_issuer, **data_related_persons, **data_offering_data}\n",
    "    return data\n",
    "\n",
    "data_fin = []\n",
    "\n",
    "for information in xml_data_list:\n",
    "    print(information)\n",
    "    root = ET.fromstring(information)\n",
    "    data_fin.append(xml_parse(root))\n",
    "\n",
    "df_main = pd.DataFrame(data_fin)\n",
    "#pd.set_option('display.max_columns', 500)\n",
    "# A very inefficient way to reorganize the columns\n",
    "#df_main.reindex(([\"Central Index Key\", \"Name of the Entity\", \"Address\", \"Address - Specification\", \"City\", \"State or Country - Physical Location\", \"State or Country - Full - Physical Location\", \"Zip Code / Postal Code\", \"Issuer Phone Number\", \"State or Country - Legal Jurisdiction\", \"Previous Names Used by the Issuer\", \"Previous Names from EDGAR\", \"Type of the Entity\", \"Type of the Entity - Specification\", \"Industry\", \"Revenue Range of the Entity\", \"Federal Exemption or Exclusions Claimed by the Entity\", \"Is the Entry an Amendment to Another Filing?\", \"Date of the First Sale Under this Filing\", \"Is the Offering Duration Intended to be More Than a Year?\", \"Is the Entity Offering Equity\", \"Is the Entity Creating or Managing a Pooled Fund\", \"Is the Offering Part of a Business Combination Transaction?\", \"Is the Offering Part of a Business Combination Transaction? - Clarification\", \"Minimum Investment Amount Accepted\", \"Entities Compensated for Selling the Securities\", \"Total Amount Offered\", \"Total Amount Sold So Far\", \"Total Amount Remaining to be sold\", \"Clarifications Regarding the Offering and Sales amounts\", \"Are Non-accredited Investors Participating in the Offering?\", \"Number of Investors Who Already Invested Under Current Offering\", \"Commision Amount Paid for Sales\", \"Finder's Fees Amount Paid\", \"Clarification Regarding the Finder's Fees Amount Paid\", \"Amount of the Raised Capital Already Used for a Purpose\", \"Clarification Regarding the Amount of the Raised Capital Already Used for a Purpose\", \"Name of the Entity Representative Signing the Filing\", \"Name of the Issuer Entity\", \"Name of the Person Signing\", \"Name of the Person Signing - Affirmation\", \"Title of the Person Signing\", \"Date the Form Was Signed\", \"First Name - Person 1\", \"Last Name - Person 1\", \"Associated Address - Person 1\", \"Associated Address - Specification - Person 1\", \"Associated City - Person 1\", \"Associated State or Country - Person 1\", \"Associated State or Country - Full - Person 1\", \"Associated Zip Code - Person 1\", \"Relationship 1 with the Entity - Person 1\", \"Relationship 2 with the Entity - Person 1\", \"Relationship 3 with the Entity - Person 1\", \"Clarification of the relationship - Person 1\", \"First Name - Person 2\", \"Last Name - Person 2\", \"Associated Address - Person 2\", \"Associated Address - Specification - Person 2\", \"Associated City - Person 2\", \"Associated State or Country - Person 2\", \"Associated State or Country - Full - Person 2\", \"Associated Zip Code - Person 2\", \"Relationship 1 with the Entity - Person 2\", \"Relationship 2 with the Entity - Person 2\", \"Clarification of the relationship - Person 2\", \"First Name - Person 3\", \"Last Name - Person 3\", \"Associated Address - Person 3\", \"Associated Address - Specification - Person 3\", \"Associated City - Person 3\", \"Associated State or Country - Person 3\", \"Associated State or Country - Full - Person 3\", \"Associated Zip Code - Person 3\", \"Relationship 1 with the Entity - Person 3\", \"Relationship 2 with the Entity - Person 3\", \"Clarification of the relationship - Person 3\", \"First Name - Person 4\", \"Last Name - Person 4\", \"Associated Address - Person 4\", \"Associated Address - Specification - Person 4\", \"Associated City - Person 4\", \"Associated State or Country - Person 4\", \"Associated State or Country - Full - Person 4\", \"Associated Zip Code - Person 4\", \"Relationship 1 with the Entity - Person 4\", \"Clarification of the relationship - Person 4\", \"First Name - Person 5\", \"Last Name - Person 5\", \"Associated Address - Person 5\", \"Associated Address - Specification - Person 5\", \"Associated City - Person 5\", \"Associated State or Country - Person 5\", \"Associated State or Country - Full - Person 5\", \"Associated Zip Code - Person 5\", \"Relationship 1 with the Entity - Person 5\", \"Clarification of the relationship - Person 5\"]), axis=1)\n",
    "\n",
    "# Cleaning the data\n",
    "df_main = df_main.fillna(\"N/A\")\n",
    "for column in df_main.columns:\n",
    "    df_main[column] = df_main[column].apply(lambda x: x[0] if isinstance(x, tuple) else x)\n",
    "\n",
    "df_main = df_main.replace(\"None\", \"N/A\")\n",
    "\n",
    "redundant_strings = [\"/s/\", \"/bem/\", \"c/o\", \"n/a\"]\n",
    "for x in redundant_strings:\n",
    "    df_main = df_main.replace(x, \"\", regex=True)\n",
    "\n",
    "df_main = df_main.replace(\"\", \"N/A\")\n",
    "df_main = df_main.fillna(\"N/A\")\n",
    "df_main.to_csv(\"cleaned_data.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
